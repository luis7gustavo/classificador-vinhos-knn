# Classifica√ß√£o de Vinhos com KNN Otimizado

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python">
  <img src="https://img.shields.io/badge/scikit--learn-F7931E?style=for-the-badge&logo=scikit-learn&logoColor=white" alt="Scikit-learn">
  <img src="https://img.shields.io/badge/Pandas-150458?style=for-the-badge&logo=pandas&logoColor=white" alt="Pandas">
  <img src="https://img.shields.io/badge/Matplotlib-007ACC?style=for-the-badge&logo=matplotlib&logoColor=white" alt="Matplotlib">
  <img src="https://img.shields.io/badge/Seaborn-094158?style=for-the-badge&logo=seaborn&logoColor=white" alt="Seaborn">
</p>

## üìä Sobre o Projeto

Este projeto demonstra um pipeline completo de Machine Learning para classificar vinhos em tr√™s categorias distintas com base em suas caracter√≠sticas qu√≠micas. A solu√ß√£o utiliza o algoritmo **K-Nearest Neighbors (KNN)** e enfatiza a import√¢ncia do pr√©-processamento de dados e da otimiza√ß√£o de hiperpar√¢metros para alcan√ßar alta performance.

O objetivo principal √© construir um modelo preditivo robusto, partindo da an√°lise explorat√≥ria at√© a avalia√ß√£o final, e estrutur√°-lo como um projeto de software modular e replic√°vel.

## üî¨ Metodologia

O pipeline do projeto foi estruturado nas seguintes etapas principais:

### 1Ô∏è‚É£ **Carregamento e Pr√©-processamento**
- Carregamento do dataset `wine.data`.
- Divis√£o dos dados em conjuntos de treino e teste (75% / 25%).
- **Escalonamento de Features**: Aplica√ß√£o do `StandardScaler` para normalizar as escalas das vari√°veis, um passo crucial para algoritmos baseados em dist√¢ncia como o KNN.

### 2Ô∏è‚É£ **Otimiza√ß√£o de Hiperpar√¢metros**
- Utiliza√ß√£o de **Grid Search com Valida√ß√£o Cruzada (5-fold)** para encontrar o valor √≥timo de `k` (n√∫mero de vizinhos).
- O espa√ßo de busca para `k` foi definido de 1 a 30.

### 3Ô∏è‚É£ **Treinamento e Avalia√ß√£o**
- Treinamento do modelo KNN final com o melhor valor de `k` encontrado.
- Avalia√ß√£o completa no conjunto de teste, utilizando m√©tricas como Acur√°cia, Precis√£o, Recall, F1-Score e a Matriz de Confus√£o.

### 4Ô∏è‚É£ **Visualiza√ß√£o de Resultados**
- Gera√ß√£o de gr√°ficos para analisar a distribui√ß√£o das features, o impacto do escalonamento, a rela√ß√£o entre `k` e a acur√°cia, e um heatmap da matriz de confus√£o para interpretar os erros de classifica√ß√£o.

## üöÄ Resultados

O modelo otimizado demonstrou uma performance excelente, com uma **acur√°cia de 95.56%** no conjunto de teste. O valor √≥timo de **K=18** foi identificado como o que melhor generaliza para novos dados, conforme a curva de acur√°cia.

| M√©trica               | Valor  |
| --------------------- | ------ |
| Acur√°cia              | 0.9556 |
| Precis√£o (Ponderada)  | 0.9587 |
| Recall (Ponderado)    | 0.9556 |
| F1-Score (Ponderado)  | 0.9551 |

<p align="center">
  <img src="https://raw.githubusercontent.com/seu-usuario/classificador_de_vinhos_knn/main/visualizations/confusion_matrix.png" alt="Matriz de Confus√£o" width="400"/>
  <img src="https://raw.githubusercontent.com/seu-usuario/classificador_de_vinhos_knn/main/visualizations/accuracy_vs_k.png" alt="Acur√°cia vs. K" width="400"/>
</p>

**Observa√ß√£o:** Para que as imagens acima apare√ßam, voc√™ precisa fazer o upload do reposit√≥rio para o GitHub e substituir `seu-usuario/classificador_de_vinhos_knn` pelo caminho real do seu reposit√≥rio.

## üìÇ Estrutura do Projeto
